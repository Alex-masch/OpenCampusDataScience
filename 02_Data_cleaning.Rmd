---
title: "Data_cleaning"
output:
  pdf_document: default
  html_document: default
  word_document: default
---
# Datenstruktur und Missings

```{r Datenstruktur nochmal anschauen}

skim(umsatzdaten_kiwo_wetter)


# Wir haben 10899 Umsatzdatensätze von 2121 Tagen. Wir bekommen durch fehlende Wetterdaten (besonders: 669 fehlende Wettercodes) insgesamt 2602 Datensätze ohne Wettercode--> Wenn wir also alle Datensätze fallen lassen, die hier fehlende Daten haben, reduzieren wir die Datenbasis erheblich

library(DataExplorer)
plot_missing(umsatzdaten_kiwo_wetter)

```

# Analyse der Ausreißer

```{r Ausreißeranalyse}
boxplot(umsatzdaten_kiwo_wetter$Temperatur)
boxplot(umsatzdaten_kiwo_wetter$Bewoelkung)
boxplot(umsatzdaten_kiwo_wetter$Windgeschwindigkeit)
# Windgeschwindigkeit hat ein paar Ausreißer, der Rest ok

boxplot(umsatzdaten_kiwo_wetter$Umsatz)
#Ups, das sieht nicht gut aus... Probleme

ggplot(umsatzdaten_kiwo_wetter) + 
geom_boxplot(aes(x=as.factor(Warengruppe), y=Umsatz))

#Auch auf Ebene der Warengruppen bleiben hier Probleme in der Datenqualität beim Umsatz 
#TODO Entscheidung für Umgehen mit Ausreißern in Umsatz-Daten treffen

#teste, ob man bestimmte Warengruppe zusammenfassen kann
#Mittelwertsunterschiede im Umsatz pro Gruppe
diff<-aov(Umsatz~Warengruppe, data=umsatzdaten_kiwo_wetter)
TukeyHSD(diff)
#Interpretation: Alle Unterschiede sig., entsprechend macht es keinen Sinn, Warengruppen zusammenzufassen.
```






Delete all rows with n/a in Wettercode

**Anmerkung AL dazu**: Warum Datensätze ohne Wettercode komplett löschen? damit wird die Datenbasis um 2602 Messpunkte kleiner.

Alternative 1: Methode nutzen, die mit Missings umgehen kann (z.B. FIML). Dann könnte man immerhin noch die Information aus den Beobachtungen, die nicht vollständig so gut wie möglich nutzen. Das geht aber nicht mit lm().

Alternative 2: bei den lm-calls jeweils als Argument einfügen: na.action=na.exclude. Vorteil: Datensatz bleibt so, wie er ist, aber in den lm-calls werden trotzdem nur die vollständigen Beobachtungen genutzt.

Alternative 3: Missings in den Wettercodes rekonstruieren, z.B. aus Bewölkung und Temperatur --> dazu muss man aber sicher wissen, was die Wettercodes bedeuten... hmmmm

Alternative 4: Missings auf einen bestimmten Wert setzen, welchen?

--> Gespräch am 17.5.2021: Wir ignorieren die Wettercodes, nehmen an, dass sie sich aus Bewölkung, Temperatur und Windgeschwindigkeit zusammensetzen und nutzen sie im Moment nicht weiter.


```{r }
#Im Dataframe wetter n/a löschen
#umsatzdaten_kiwo_wetter <- umsatzdaten_kiwo_wetter %>% drop_na(Wettercode) #AL: wegen Anmerkung oben auskommentiert

```



# Datenaufbereitung
KielerWoche dichotomisieren; Bewoelkung, Temperatur und Windgeschwindigkeit mittlere Werte imputieren

```{r Vorschlag cleaning}
#KielerWoche-Variable auf 0/1 codieren

umsatzdaten_kiwo_wetter$KielerWoche[is.na(umsatzdaten_kiwo_wetter$KielerWoche)] <- 0

#Bewoelkung-Variable NAs auf mean(Bewoelkung) kodieren (mittlere Werte im Datensatz), denn: es sind nur 10 Datensätze, die das betrifft und in diesen Fällen gibt es keinen klaren Temperaturtrend

umsatzdaten_kiwo_wetter$Bewoelkung[is.na(umsatzdaten_kiwo_wetter$Bewoelkung)] <- mean(umsatzdaten_kiwo_wetter$Bewoelkung, na.rm=TRUE)


umsatzdaten_kiwo_wetter$Temperatur[is.na(umsatzdaten_kiwo_wetter$Temperatur)] <- mean(umsatzdaten_kiwo_wetter$Temperatur, na.rm=TRUE)

umsatzdaten_kiwo_wetter$Windgeschwindigkeit[is.na(umsatzdaten_kiwo_wetter$Windgeschwindigkeit)] <- mean(umsatzdaten_kiwo_wetter$Windgeschwindigkeit, na.rm=TRUE)


skim(umsatzdaten_kiwo_wetter)#Datenstruktur nochmal prüfen


```


