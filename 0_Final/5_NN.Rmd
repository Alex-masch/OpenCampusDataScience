
# Neuronale Netze

# Vorbereitung

## Installation von Python und TensorFlow (nur einmalig nötig, im Hintergrund)
```{r, include=F}
#install.packages("reticulate")
library(reticulate)
# Installation von miniconda (falls nicht vorhanden)
#install_miniconda(update=TRUE)
#miniconda_update(path = miniconda_path()) #ggf. notwendig, miniconda upzudaten
# Anlegen einer speziellen Python Umgebung
conda_create("r-reticulate")
# Installieren der Pakete in der angelegten Umgebung
conda_install("r-reticulate", "pandas")
conda_install("r-reticulate", "numpy")
conda_install("r-reticulate", "tensorflow")
conda_install("r-reticulate", "h5py")
 
# Verwenden der speziellen Python Umgebung die zuvor erstellt wurde
use_condaenv("r-reticulate")
```


## Benötigte Pakete laden (im Hintergrund)
```{r , include=F}
library(ggplot2)
library(Metrics)
```



## Daten aufbereiten (im Hintergrund)
```{r , include=F}
### Preparation of the environment


#Lade benöätige library über Liste und for-Schleife
pkgs <- c('readr', 'fastDummies')

for(pkg in pkgs) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg)
    library(pkg, character.only = TRUE)
  }
}


data <- data2 #Datensatz
pred_data<-pred_data2 #Datensatz für spätere Vorhersage
pred_data$Umsatz <-NA

### Data preparation

# encoding der Variablen in Dummy Variablen
dummy_list <- c("Warengruppe","Wochentag")
data_dummy = dummy_cols(data, dummy_list)
pred_data_dummy = dummy_cols(pred_data, dummy_list)



#Definition der Listen fuer dummy encodete Variablen (damit einfacher zu handeln)
warengruppe_dummies = c('Warengruppe_2', 'Warengruppe_3', 'Warengruppe_4', 'Warengruppe_5', 'Warengruppe_6')
wochentag_dummies = c('Wochentag_2', 'Wochentag_3', 'Wochentag_4', 'Wochentag_5', 'Wochentag_6', 'Wochentag_7')



### Selection of the Feature Variables and the Label Variable

#Auswahl der features (die unabhängigen Var wird zur Vorhersage der abhänigen genutzt)

features <-  c("Bewoelkung", "KielerWoche", "Temperatur", "Windgeschwindigkeit", warengruppe_dummies, wochentag_dummies)    # unabhängige Variablen zur Vorhersage
labels <- "Umsatz"                                                                                                          # zu vorhersagende Variable


### Selecion of Training, Validation and Test Data

#gebe Datendummy aus

str(data_dummy)
str(pred_data_dummy)

# setze Zufallsgenerator auf festen Wert, damit random split is always the same
set.seed(1)


# Dataset durcheinander würfeln um eine Random-Reihnfolge zu erhalten
new_row_order <- sample(nrow(data_dummy))
data_dummy <- data_dummy[new_row_order, ]

# erstelle Hilfs-Zufalls-Variable assignment (Besitzt Wert 1, 2 oder 3)
assignment <- sample(1:3, size = nrow(data_dummy), prob = c(.7, .2, .1), replace = TRUE)

# erstelle training-, validation- & test data fuer features und labels
training_features <- data_dummy[assignment == 1, features]  #subset data to training indices only
training_labels <- data_dummy[assignment == 1, labels]       #subset data to training indices only

validation_features <- data_dummy[assignment == 2, features]  # subset data to validation indices only
validation_labels <- data_dummy[assignment == 2, labels]  # subset data to validation indices only

test_features <- data_dummy[assignment == 3, features]   # subset data to test indices only
test_labels <- data_dummy[assignment == 3, labels]   # subset data to test indices only


pred_data_features <- pred_data_dummy   # Vorbereitung Datensatz für "echte" Vorhersage
pred_data_features$Wochentag_1 <-0
pred_data_features$Wochentag_2 <-0
pred_data_features$Wochentag_4 <-0
pred_data_features$Wochentag_6 <-0

pred_data_features <- as_tibble(pred_data_features[features])
pred_data_labels <- as_tibble(pred_data_dummy[labels])   




```



# Training des Neuronalen Netzes

## Definition des Neuronalen Netzes

```{python}
# Import needed Python libraries and functions
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers.experimental import preprocessing
# Create a Normalization layer and use the means and variances of the training features for the normalization
normalizer = preprocessing.Normalization()
normalizer.adapt(r.training_features.values)
# The argument "shape" for the definition of the input layer must include the number of variables (features) used for the model. To automatically calculate this number, we use the "r.training_features.keys()", which returns the list of variable names of the dataframe "training_features". Further, the function len() returns the length of this list of variable names (i.e. the number of variables in the input).
inputs = tf.keras.Input(shape=[len(r.training_features.keys())])
# Normalization layer
x = normalizer(inputs)
# 1st hidden layer
x = Dense(10, activation='relu')(x)
x = Dropout(.2)(x)
# 2nd hidden layer
x = Dense(4, activation='relu')(x)
# Output layer
output = tf.keras.layers.Dense(1)(x)
# Model definition
model = tf.keras.Model(inputs, output)
# Ausgabe einer Zusammenfassung zur Form des Modells, das geschaetzt wird (nicht notwendig)
model.summary()
```


## Schätzung des neuronalen Netzes
```{python}
# Definition der Kosten-(Loss-)Funktion und der Optimierungsfunktion mit seinen Hyperparametern
model.compile(loss="mse", optimizer=Adam(lr=0.001))
# Schaetzung des Modells
history = model.fit(r.training_features, r.training_labels, epochs=100,
                    validation_data = (r.validation_features, r.validation_labels), verbose=0)
# Ggf. Speichern des geschaetzten Modells
model.save("python_model.h5")
```


## Auswertung der Modelloptimierung
```{r}
# Grafische Ausgabe der Modelloptimierung
# create data
data <- data.frame(val_loss = unlist(py$history$history$val_loss),
                  loss = unlist(py$history$history$loss))
# Plot
ggplot(data[-1,]) +
  geom_line( aes(x=1:length(val_loss), y=val_loss, colour = "Validation Loss" )) +
  geom_line( aes(x=1:length(loss), y=loss, colour = "Training Loss" )) +
  scale_colour_manual( values = c("Training Loss"="blue", "Validation Loss"="red") ) +
  labs(title="Loss Function Values During Optimization") +
  xlab("Iteration Number") +
  ylab("Loss") 
```


## (Ggf.) Laden eines gespeicherten Neuronalen Netzes ###
```{python}
model = tf.keras.models.load_model("python_model.h5")
```


## Auswertung der Schätzergebnisse ###
```{r}
# Schätzung der (normierten) Preise für die Trainings- und Testdaten
training_predictions <- py$model$predict(training_features)
validation_predictions <- py$model$predict(validation_features)
validation_true_predictions <- py$model$predict(pred_data_features)
# Vergleich der Gütekriterien für die Trainings- und Testdaten
cat(paste0("MAPE on the Training Data:\t", format(mape(training_labels[[1]], as.numeric(training_predictions))*100, digits=3, nsmall=2)))
cat(paste0("\nMAPE on the Validation Data:\t", format(mape(validation_labels[[1]], validation_predictions)*100, digits=3, nsmall=2)))
```

```{r}
## Grafischer vergleich der vorhergesagten und der tatsächlichen Preise für die Trainings- und Testdaten
# Zusammenstellung der Daten für die Plots
data_train <- data.frame(prediction = training_predictions, actual = training_labels[[1]])
data_test <- data.frame(prediction = validation_predictions, actual = validation_labels[[1]])
data_pred <- data.frame(prediction = validation_true_predictions)
# Plot der Ergebnisse der Trainingsdaten
ggplot(data_train[1:100,]) +
  geom_line( aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(actual), y=actual, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Training Data") +
  xlab("Case Number") +
  ylab("Sales in EUR") 
# Plot der Ergebnisse der Validierungsdaten
ggplot(data_test[1:100,]) +
  geom_line( aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(actual), y=actual, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Test Data") +
  xlab("Case Number") +
  ylab("Sales in EUR") 

```

## Prädiktion 4 (Neuronales Netz)


```{r}


pred_nn  <- dplyr::bind_cols(pred_data2, as.data.frame(data_pred)) #zusammenfügen

pred_nn<- rename(pred_nn,Prediction_Umsatz_nn = prediction)#Variablenbenennung anpassen 

#Faktoren wieder schick machen
pred_nn$Wochentag <- factor(weekdays(pred_nn$Datum),
levels=ordentlicheWoche)
pred_nn$Warengruppe <- factor(pred_nn$Warengruppe,
levels = c(1,2,3,4,5,6),
labels = Warengruppen)


anzeige <-dplyr::filter(pred_nn,Datum==ymd(20190607))
anzeige <-dplyr::select(anzeige, c("Warengruppe","Prediction_Umsatz_nn"))

pred_nn

```



[**Die Vorhersage für den ersten Tag (`r ymd(20190607)`) nach Ende der Datenreihe ist:**]{style="color: red;"}

Variablen die im NN eingehen: 
Bewoelkung
KielerWoche
Temperatur
Windgeschwindigkeit
warengruppe_dummies
wochentag_dummies



```{r echo=FALSE}
anzeige

rm(anzeige)
```
